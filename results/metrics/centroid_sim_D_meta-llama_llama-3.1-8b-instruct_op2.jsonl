{"group": "D", "topic_id": 0, "topic_size": 1893, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "essay writing", "cosine": 0.4171425700187683}
{"group": "D", "topic_id": 1, "topic_size": 24, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "medical emergency response", "cosine": 0.5222001075744629}
{"group": "D", "topic_id": 2, "topic_size": 20, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "tech support", "cosine": 0.3863496482372284}
{"group": "D", "topic_id": 3, "topic_size": 15, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "install deducer error", "cosine": 0.6577403545379639}
{"group": "D", "topic_id": 4, "topic_size": 12, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "download slides", "cosine": 0.8646488785743713}
{"group": "D", "topic_id": 5, "topic_size": 11, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "histograms in sas", "cosine": 0.6817134618759155}
{"group": "D", "topic_id": 7, "topic_size": 10, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "spinal cord injuries", "cosine": 0.7592388391494751}
{"group": "D", "topic_id": 8, "topic_size": 9, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "person years", "cosine": 0.6933251619338989}
{"group": "D", "topic_id": 9, "topic_size": 9, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "statement accomplishment", "cosine": 0.7911099195480347}
{"group": "D", "topic_id": 10, "topic_size": 9, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "parkinsons disease", "cosine": 0.2398684173822403}
{"group": "D", "topic_id": 11, "topic_size": 8, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "easy compose", "cosine": 0.42099735140800476}
{"group": "D", "topic_id": 12, "topic_size": 7, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "course completion", "cosine": 0.3170398771762848}
{"group": "D", "topic_id": 13, "topic_size": 7, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "normal approximation", "cosine": 0.621310293674469}
{"group": "D", "topic_id": 14, "topic_size": 7, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "ordinal scale", "cosine": 0.6633076071739197}
{"group": "D", "topic_id": 15, "topic_size": 6, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "multiple births", "cosine": 0.6128063201904297}
{"group": "D", "topic_id": 16, "topic_size": 6, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "slope and line", "cosine": 0.7449820637702942}
{"group": "D", "topic_id": 17, "topic_size": 6, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "getting help", "cosine": 0.5246264934539795}
{"group": "D", "topic_id": 18, "topic_size": 6, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "donor blood supply", "cosine": 0.6247763633728027}
{"group": "D", "topic_id": 19, "topic_size": 6, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "language learning", "cosine": 0.318307489156723}
{"group": "D", "topic_id": 20, "topic_size": 6, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "electron trajectories", "cosine": 0.6578999757766724}
{"group": "D", "topic_id": 21, "topic_size": 5, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "rolling dice", "cosine": 0.7767314910888672}
{"group": "D", "topic_id": 22, "topic_size": 5, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "editing demo exercises", "cosine": 0.7382852435112}
{"group": "D", "topic_id": 23, "topic_size": 5, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "email issues", "cosine": 0.5725331902503967}
{"group": "D", "topic_id": 24, "topic_size": 5, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "beta smoking", "cosine": 0.33598101139068604}
{"group": "D", "topic_id": 25, "topic_size": 5, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "graphic way control", "cosine": 0.05044235661625862}
{"group": "D", "topic_id": 26, "topic_size": 5, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "p-value adjustment", "cosine": 0.5632208585739136}
{"group": "D", "topic_id": 27, "topic_size": 5, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "halt study", "cosine": 0.8344231247901917}
{"group": "D", "topic_id": 28, "topic_size": 5, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "alzheimers prevention", "cosine": 0.7128831744194031}
{"group": "D", "topic_id": 29, "topic_size": 5, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "quiz based", "cosine": 0.1901303380727768}
{"group": "D", "topic_id": 30, "topic_size": 5, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "null hypothesis", "cosine": 0.42465946078300476}
{"group": "D", "topic_id": 31, "topic_size": 5, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "fitness performance", "cosine": 0.6656613945960999}
{"group": "D", "topic_id": 32, "topic_size": 5, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "choosing a function", "cosine": 0.30130279064178467}
{"group": "D", "topic_id": 33, "topic_size": 5, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "frequency study", "cosine": 0.688069224357605}
{"group": "D", "topic_id": 34, "topic_size": 5, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "survival probability", "cosine": 0.6701046824455261}
{"group": "D", "topic_id": 35, "topic_size": 5, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "find old posts", "cosine": 0.6036033630371094}
{"group": "D", "topic_id": 36, "topic_size": 4, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "vaccine simulation", "cosine": 0.8004531264305115}
{"group": "D", "topic_id": 37, "topic_size": 4, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "mock data", "cosine": 0.6703221201896667}
{"group": "D", "topic_id": 38, "topic_size": 4, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "module use statement", "cosine": 0.6066028475761414}
{"group": "D", "topic_id": 39, "topic_size": 4, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "fishers exact test", "cosine": 0.6583958864212036}
{"group": "D", "topic_id": 40, "topic_size": 4, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "coin flip probability", "cosine": 0.5955129861831665}
{"group": "D", "topic_id": 41, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "downloading unit solutions", "cosine": 0.6817466020584106}
{"group": "D", "topic_id": 42, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "perfect tense", "cosine": 0.2810927927494049}
{"group": "D", "topic_id": 43, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "browser issues", "cosine": 0.5084763169288635}
{"group": "D", "topic_id": 44, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "common sense", "cosine": 0.7279626727104187}
{"group": "D", "topic_id": 45, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "square vs absolute", "cosine": 0.6418649554252625}
{"group": "D", "topic_id": 46, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "professional writing", "cosine": 0.5116032361984253}
{"group": "D", "topic_id": 47, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "kind help needed", "cosine": 0.6337720155715942}
{"group": "D", "topic_id": 48, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "energy costs", "cosine": 0.14278267323970795}
{"group": "D", "topic_id": 49, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "raised nevi", "cosine": 0.4234989583492279}
{"group": "D", "topic_id": 50, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "increase dsst score", "cosine": 0.5533587336540222}
{"group": "D", "topic_id": 51, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "signrank test", "cosine": 0.5513793230056763}
{"group": "D", "topic_id": 52, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "cherrypicked data", "cosine": 0.4482308626174927}
{"group": "D", "topic_id": 53, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "cheating question", "cosine": 0.49548715353012085}
{"group": "D", "topic_id": 54, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "slice order matters", "cosine": 0.5001465678215027}
{"group": "D", "topic_id": 55, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "ratios and units", "cosine": 0.5919777750968933}
{"group": "D", "topic_id": 56, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "act and wave", "cosine": 0.3526897132396698}
{"group": "D", "topic_id": 57, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "exact vs chi", "cosine": 0.5496786832809448}
{"group": "D", "topic_id": 58, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "browser issues", "cosine": 0.4812062382698059}
{"group": "D", "topic_id": 59, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "missing data", "cosine": 0.4987041652202606}
{"group": "D", "topic_id": 60, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "percentages in mooc", "cosine": 0.4289729595184326}
{"group": "D", "topic_id": 61, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "howcome answer", "cosine": 0.6978205442428589}
{"group": "D", "topic_id": 62, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "got zeros peers", "cosine": 0.6092421412467957}
{"group": "D", "topic_id": 63, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "number question", "cosine": 0.4143969714641571}
{"group": "D", "topic_id": 64, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "prevalence calculations", "cosine": 0.581442654132843}
{"group": "D", "topic_id": 65, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "predictive power", "cosine": 0.15047192573547363}
{"group": "D", "topic_id": 66, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "alzheimers disease", "cosine": 0.5931581258773804}
{"group": "D", "topic_id": 67, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "wait bug fixed", "cosine": 0.5524789094924927}
{"group": "D", "topic_id": 68, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "standard normal chart", "cosine": 0.7349894046783447}
{"group": "D", "topic_id": 69, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "journal legality", "cosine": 0.6072627305984497}
{"group": "D", "topic_id": 70, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "success probability", "cosine": 0.7445347309112549}
{"group": "D", "topic_id": 71, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "pond waste management", "cosine": 0.47488999366760254}
{"group": "D", "topic_id": 72, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "childhood conduct", "cosine": 0.491413950920105}
{"group": "D", "topic_id": 73, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "deserved zeros", "cosine": 0.7173686623573303}
{"group": "D", "topic_id": 74, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "missing solutions", "cosine": 0.5948489904403687}
{"group": "D", "topic_id": 75, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "treat injuries", "cosine": 0.4067877531051636}
{"group": "D", "topic_id": 76, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "statement accomplishment", "cosine": 0.6379656791687012}
{"group": "D", "topic_id": 77, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "outlier detection", "cosine": 0.47128885984420776}
{"group": "D", "topic_id": 78, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "skewed results", "cosine": 0.4305090606212616}
{"group": "D", "topic_id": 79, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "download module", "cosine": 0.8279401659965515}
{"group": "D", "topic_id": 80, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "editing text", "cosine": 0.5672435164451599}
{"group": "D", "topic_id": 81, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "update reference books", "cosine": 0.6743056774139404}
{"group": "D", "topic_id": 82, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "rescuetime uninstall", "cosine": 0.6368010640144348}
{"group": "D", "topic_id": 83, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "pab independence", "cosine": 0.6613045334815979}
{"group": "D", "topic_id": 84, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "typo in table", "cosine": 0.4612426459789276}
{"group": "D", "topic_id": 85, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "lecture hints", "cosine": 0.6011138558387756}
{"group": "D", "topic_id": 86, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "submit answers", "cosine": 0.5127801299095154}
{"group": "D", "topic_id": 87, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "statistical inference", "cosine": 0.3963695168495178}
{"group": "D", "topic_id": 88, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "normality assumption", "cosine": 0.42850223183631897}
{"group": "D", "topic_id": 89, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "week challenges", "cosine": 0.6432390213012695}
{"group": "D", "topic_id": 90, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "large question", "cosine": 0.3175160884857178}
{"group": "D", "topic_id": 91, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "page access", "cosine": 0.3392984867095947}
{"group": "D", "topic_id": 92, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "blood sugar levels", "cosine": 0.3323245048522949}
{"group": "D", "topic_id": 93, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 2, "label": "discordant pairs", "cosine": 0.31689006090164185}
