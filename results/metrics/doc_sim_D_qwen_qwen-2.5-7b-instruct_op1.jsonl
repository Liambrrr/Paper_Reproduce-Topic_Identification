{"meta": {"group": "D", "topic_id": 0, "topic_size": 1893, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "peer grading", "stats": {"n_snippets": 10, "mean": 0.3705638647079468, "min": 0.04127684235572815, "max": 0.6161381602287292}}
{"meta": {"group": "D", "topic_id": 1, "topic_size": 24, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "resuscitation equipment", "stats": {"n_snippets": 10, "mean": 0.274557888507843, "min": 0.04677589237689972, "max": 0.5941957831382751}}
{"meta": {"group": "D", "topic_id": 2, "topic_size": 20, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "tech support issues", "stats": {"n_snippets": 10, "mean": 0.30279651284217834, "min": 0.07966932654380798, "max": 0.5267723798751831}}
{"meta": {"group": "D", "topic_id": 3, "topic_size": 15, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "deducer installation issues", "stats": {"n_snippets": 10, "mean": 0.42508426308631897, "min": 0.2007075995206833, "max": 0.6712738275527954}}
{"meta": {"group": "D", "topic_id": 4, "topic_size": 12, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "slides download", "stats": {"n_snippets": 10, "mean": 0.6477170586585999, "min": 0.4541669487953186, "max": 0.9592545628547668}}
{"meta": {"group": "D", "topic_id": 5, "topic_size": 11, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "histograms and bars", "stats": {"n_snippets": 10, "mean": 0.5707079172134399, "min": 0.4896760582923889, "max": 0.6417609453201294}}
{"meta": {"group": "D", "topic_id": 6, "topic_size": 10, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "pediatric emergencies", "stats": {"n_snippets": 10, "mean": 0.269419401884079, "min": 0.12840253114700317, "max": 0.4343165159225464}}
{"meta": {"group": "D", "topic_id": 7, "topic_size": 10, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "spinal cord injuries", "stats": {"n_snippets": 10, "mean": 0.6053305864334106, "min": 0.3465242087841034, "max": 0.7532583475112915}}
{"meta": {"group": "D", "topic_id": 8, "topic_size": 9, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "person years follow", "stats": {"n_snippets": 9, "mean": 0.5432955622673035, "min": 0.45056456327438354, "max": 0.7554824948310852}}
{"meta": {"group": "D", "topic_id": 9, "topic_size": 9, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "statement accomplishment", "stats": {"n_snippets": 9, "mean": 0.6147881150245667, "min": 0.35201495885849, "max": 0.8462156653404236}}
{"meta": {"group": "D", "topic_id": 10, "topic_size": 9, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "case control study", "stats": {"n_snippets": 9, "mean": 0.2481204867362976, "min": 0.06704717874526978, "max": 0.42640846967697144}}
{"meta": {"group": "D", "topic_id": 11, "topic_size": 8, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "submit finished", "stats": {"n_snippets": 8, "mean": 0.49297475814819336, "min": 0.06984005123376846, "max": 0.5821806192398071}}
{"meta": {"group": "D", "topic_id": 12, "topic_size": 7, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "student feedback", "stats": {"n_snippets": 7, "mean": 0.19406597316265106, "min": 0.09066589921712875, "max": 0.3587685227394104}}
{"meta": {"group": "D", "topic_id": 13, "topic_size": 7, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "normal approx binom", "stats": {"n_snippets": 7, "mean": 0.5968919992446899, "min": 0.5206620693206787, "max": 0.6512876152992249}}
{"meta": {"group": "D", "topic_id": 14, "topic_size": 7, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "ordinal data", "stats": {"n_snippets": 7, "mean": 0.498280793428421, "min": 0.313204824924469, "max": 0.642818808555603}}
{"meta": {"group": "D", "topic_id": 15, "topic_size": 6, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "multiple births", "stats": {"n_snippets": 6, "mean": 0.4206053912639618, "min": 0.0753391832113266, "max": 0.6190690398216248}}
{"meta": {"group": "D", "topic_id": 16, "topic_size": 6, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "slope calculation", "stats": {"n_snippets": 6, "mean": 0.542107880115509, "min": 0.3920656442642212, "max": 0.7603926658630371}}
{"meta": {"group": "D", "topic_id": 17, "topic_size": 6, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "getting help", "stats": {"n_snippets": 6, "mean": 0.36605212092399597, "min": 0.15893760323524475, "max": 0.5701563954353333}}
{"meta": {"group": "D", "topic_id": 18, "topic_size": 6, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "donor blood", "stats": {"n_snippets": 6, "mean": 0.4482823610305786, "min": 0.3393169641494751, "max": 0.5300998687744141}}
{"meta": {"group": "D", "topic_id": 19, "topic_size": 6, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "assignment issues", "stats": {"n_snippets": 6, "mean": 0.18294398486614227, "min": 0.08077231794595718, "max": 0.2591626048088074}}
{"meta": {"group": "D", "topic_id": 20, "topic_size": 6, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "electron trajectories", "stats": {"n_snippets": 6, "mean": 0.5349597334861755, "min": 0.26968491077423096, "max": 0.6976271867752075}}
{"meta": {"group": "D", "topic_id": 21, "topic_size": 5, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "dice rolling", "stats": {"n_snippets": 5, "mean": 0.6181849241256714, "min": 0.5189908742904663, "max": 0.7538203597068787}}
{"meta": {"group": "D", "topic_id": 22, "topic_size": 5, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "editing practice", "stats": {"n_snippets": 5, "mean": 0.47857722640037537, "min": 0.3282220661640167, "max": 0.5831509828567505}}
{"meta": {"group": "D", "topic_id": 23, "topic_size": 5, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "webmail issues", "stats": {"n_snippets": 5, "mean": 0.3381233811378479, "min": 0.18609833717346191, "max": 0.5767530202865601}}
{"meta": {"group": "D", "topic_id": 24, "topic_size": 5, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "beta comparison", "stats": {"n_snippets": 5, "mean": 0.3602920174598694, "min": 0.11562193185091019, "max": 0.5662899613380432}}
{"meta": {"group": "D", "topic_id": 25, "topic_size": 5, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "correlation analysis", "stats": {"n_snippets": 5, "mean": 0.2991407513618469, "min": 0.028544161468744278, "max": 0.4737846553325653}}
{"meta": {"group": "D", "topic_id": 26, "topic_size": 5, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "pvalue adjustment", "stats": {"n_snippets": 5, "mean": 0.5003575086593628, "min": 0.2961815297603607, "max": 0.8173567056655884}}
{"meta": {"group": "D", "topic_id": 27, "topic_size": 5, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "study halt", "stats": {"n_snippets": 5, "mean": 0.7017444968223572, "min": 0.5761772990226746, "max": 0.8242778182029724}}
{"meta": {"group": "D", "topic_id": 28, "topic_size": 5, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "antiinflammatory drugs", "stats": {"n_snippets": 5, "mean": 0.6293761134147644, "min": 0.557386040687561, "max": 0.692642092704773}}
{"meta": {"group": "D", "topic_id": 29, "topic_size": 5, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "quiz feedback", "stats": {"n_snippets": 5, "mean": 0.14700119197368622, "min": -0.012786343693733215, "max": 0.2990080416202545}}
{"meta": {"group": "D", "topic_id": 30, "topic_size": 5, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "hypothesis testing", "stats": {"n_snippets": 5, "mean": 0.312921941280365, "min": 0.1875455379486084, "max": 0.5454926490783691}}
{"meta": {"group": "D", "topic_id": 31, "topic_size": 5, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "fitness performance", "stats": {"n_snippets": 5, "mean": 0.5733101963996887, "min": 0.3834707736968994, "max": 0.6934620141983032}}
{"meta": {"group": "D", "topic_id": 32, "topic_size": 5, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "choosing function", "stats": {"n_snippets": 5, "mean": 0.2805767059326172, "min": 0.12955282628536224, "max": 0.4724775552749634}}
{"meta": {"group": "D", "topic_id": 33, "topic_size": 5, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "frequency explanation", "stats": {"n_snippets": 5, "mean": 0.4591560363769531, "min": 0.32074975967407227, "max": 0.6024441719055176}}
{"meta": {"group": "D", "topic_id": 34, "topic_size": 5, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "survival probability", "stats": {"n_snippets": 5, "mean": 0.5392912030220032, "min": 0.34427452087402344, "max": 0.6262050271034241}}
{"meta": {"group": "D", "topic_id": 35, "topic_size": 5, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "post search", "stats": {"n_snippets": 5, "mean": 0.36784255504608154, "min": 0.2658870220184326, "max": 0.4703912138938904}}
{"meta": {"group": "D", "topic_id": 36, "topic_size": 4, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "simulation studies", "stats": {"n_snippets": 4, "mean": 0.41491320729255676, "min": 0.32424604892730713, "max": 0.5001593828201294}}
{"meta": {"group": "D", "topic_id": 37, "topic_size": 4, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "mock data", "stats": {"n_snippets": 4, "mean": 0.5312576293945312, "min": 0.4490167796611786, "max": 0.6212259531021118}}
{"meta": {"group": "D", "topic_id": 38, "topic_size": 4, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "module usage", "stats": {"n_snippets": 4, "mean": 0.5346052646636963, "min": 0.45015501976013184, "max": 0.5935534238815308}}
{"meta": {"group": "D", "topic_id": 39, "topic_size": 4, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "fisher's exact test", "stats": {"n_snippets": 4, "mean": 0.46199703216552734, "min": 0.23861412703990936, "max": 0.5570352673530579}}
{"meta": {"group": "D", "topic_id": 40, "topic_size": 4, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "coin flip outcomes", "stats": {"n_snippets": 4, "mean": 0.4883495271205902, "min": 0.3540315330028534, "max": 0.577282190322876}}
{"meta": {"group": "D", "topic_id": 41, "topic_size": 3, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "download issues", "stats": {"n_snippets": 3, "mean": 0.43673086166381836, "min": 0.28188878297805786, "max": 0.5390928983688354}}
{"meta": {"group": "D", "topic_id": 42, "topic_size": 3, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "tense changes", "stats": {"n_snippets": 3, "mean": 0.26356980204582214, "min": 0.031662486493587494, "max": 0.4875383973121643}}
{"meta": {"group": "D", "topic_id": 43, "topic_size": 3, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "browser submission issues", "stats": {"n_snippets": 3, "mean": 0.3533411920070648, "min": 0.25313299894332886, "max": 0.4559139609336853}}
{"meta": {"group": "D", "topic_id": 44, "topic_size": 3, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "common sense", "stats": {"n_snippets": 3, "mean": 0.6037551164627075, "min": 0.550006628036499, "max": 0.6829513311386108}}
{"meta": {"group": "D", "topic_id": 45, "topic_size": 3, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "absolute distance", "stats": {"n_snippets": 3, "mean": 0.372769832611084, "min": 0.2325330376625061, "max": 0.48737633228302}}
{"meta": {"group": "D", "topic_id": 46, "topic_size": 3, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "fiveletter words", "stats": {"n_snippets": 3, "mean": 0.5604129433631897, "min": 0.4222610592842102, "max": 0.8344710469245911}}
{"meta": {"group": "D", "topic_id": 47, "topic_size": 3, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "help requests", "stats": {"n_snippets": 3, "mean": 0.4538458287715912, "min": 0.43662598729133606, "max": 0.46245574951171875}}
{"meta": {"group": "D", "topic_id": 48, "topic_size": 3, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "amputee sprinting", "stats": {"n_snippets": 3, "mean": 0.48382291197776794, "min": 0.30109620094299316, "max": 0.5905845165252686}}
{"meta": {"group": "D", "topic_id": 49, "topic_size": 3, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "raised nevi assessment", "stats": {"n_snippets": 3, "mean": 0.4810403287410736, "min": 0.37976914644241333, "max": 0.5909138917922974}}
{"meta": {"group": "D", "topic_id": 50, "topic_size": 3, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "dsst score improvement", "stats": {"n_snippets": 3, "mean": 0.47626662254333496, "min": 0.3881606459617615, "max": 0.5592321753501892}}
{"meta": {"group": "D", "topic_id": 51, "topic_size": 3, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "signrank test", "stats": {"n_snippets": 3, "mean": 0.4322606027126312, "min": 0.33206599950790405, "max": 0.6308538913726807}}
{"meta": {"group": "D", "topic_id": 52, "topic_size": 3, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "data analysis", "stats": {"n_snippets": 3, "mean": 0.31197309494018555, "min": 0.27471810579299927, "max": 0.3543437421321869}}
{"meta": {"group": "D", "topic_id": 53, "topic_size": 3, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "cheating question", "stats": {"n_snippets": 3, "mean": 0.3737998902797699, "min": 0.1331150233745575, "max": 0.745227575302124}}
{"meta": {"group": "D", "topic_id": 54, "topic_size": 3, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "combinatorics", "stats": {"n_snippets": 3, "mean": 0.3525148332118988, "min": 0.2755148410797119, "max": 0.39796119928359985}}
{"meta": {"group": "D", "topic_id": 55, "topic_size": 3, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "module doubts", "stats": {"n_snippets": 3, "mean": 0.2591499090194702, "min": 0.10103727877140045, "max": 0.35175567865371704}}
{"meta": {"group": "D", "topic_id": 56, "topic_size": 3, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "act sequence", "stats": {"n_snippets": 3, "mean": 0.16147102415561676, "min": 0.04990294575691223, "max": 0.27418774366378784}}
{"meta": {"group": "D", "topic_id": 57, "topic_size": 3, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "chi-square vs exact", "stats": {"n_snippets": 3, "mean": 0.5265287756919861, "min": 0.5082542300224304, "max": 0.5502303838729858}}
{"meta": {"group": "D", "topic_id": 58, "topic_size": 3, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "mobile app issues", "stats": {"n_snippets": 3, "mean": 0.29385629296302795, "min": 0.28496670722961426, "max": 0.298550546169281}}
{"meta": {"group": "D", "topic_id": 59, "topic_size": 3, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "missing data", "stats": {"n_snippets": 3, "mean": 0.41896772384643555, "min": 0.27408915758132935, "max": 0.5939955115318298}}
{"meta": {"group": "D", "topic_id": 60, "topic_size": 3, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "percentages decimals", "stats": {"n_snippets": 3, "mean": 0.6479767560958862, "min": 0.6479767560958862, "max": 0.6479767560958862}}
{"meta": {"group": "D", "topic_id": 61, "topic_size": 3, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "howcome answers", "stats": {"n_snippets": 3, "mean": 0.5290434956550598, "min": 0.44728609919548035, "max": 0.6601693630218506}}
{"meta": {"group": "D", "topic_id": 62, "topic_size": 3, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "paper clarity", "stats": {"n_snippets": 3, "mean": 0.46684303879737854, "min": 0.4668430685997009, "max": 0.4668430685997009}}
{"meta": {"group": "D", "topic_id": 63, "topic_size": 3, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "numerators and numbers", "stats": {"n_snippets": 3, "mean": 0.32174238562583923, "min": 0.21200557053089142, "max": 0.41552525758743286}}
{"meta": {"group": "D", "topic_id": 64, "topic_size": 3, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "epidemiology calculations", "stats": {"n_snippets": 3, "mean": 0.3404477834701538, "min": 0.29435670375823975, "max": 0.41518789529800415}}
{"meta": {"group": "D", "topic_id": 65, "topic_size": 2, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "diagnostic tests", "stats": {"n_snippets": 2, "mean": 0.3477005362510681, "min": 0.28735458850860596, "max": 0.4080464839935303}}
{"meta": {"group": "D", "topic_id": 66, "topic_size": 2, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "neonatal malignancy", "stats": {"n_snippets": 2, "mean": 0.2206001877784729, "min": 0.1104731634259224, "max": 0.330727219581604}}
{"meta": {"group": "D", "topic_id": 67, "topic_size": 2, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "assignment early", "stats": {"n_snippets": 2, "mean": 0.43580037355422974, "min": 0.336933970451355, "max": 0.5346667766571045}}
{"meta": {"group": "D", "topic_id": 68, "topic_size": 2, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "standard normal chart", "stats": {"n_snippets": 2, "mean": 0.6341344118118286, "min": 0.6039055585861206, "max": 0.6643632650375366}}
{"meta": {"group": "D", "topic_id": 69, "topic_size": 2, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "journal article review", "stats": {"n_snippets": 2, "mean": 0.41019436717033386, "min": 0.3264821171760559, "max": 0.4939066171646118}}
{"meta": {"group": "D", "topic_id": 70, "topic_size": 2, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "zscore probability", "stats": {"n_snippets": 2, "mean": 0.4030352830886841, "min": 0.2771877348423004, "max": 0.5288828611373901}}
{"meta": {"group": "D", "topic_id": 71, "topic_size": 2, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "climate health", "stats": {"n_snippets": 2, "mean": 0.34515243768692017, "min": 0.2829909920692444, "max": 0.40731388330459595}}
{"meta": {"group": "D", "topic_id": 72, "topic_size": 2, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "childhood conduct", "stats": {"n_snippets": 2, "mean": 0.4174925684928894, "min": 0.221488818526268, "max": 0.6134963035583496}}
{"meta": {"group": "D", "topic_id": 73, "topic_size": 2, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "grading disputes", "stats": {"n_snippets": 2, "mean": 0.24583715200424194, "min": 0.10981971025466919, "max": 0.3818545937538147}}
{"meta": {"group": "D", "topic_id": 74, "topic_size": 2, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "solutions mismatch", "stats": {"n_snippets": 2, "mean": 0.4116278290748596, "min": 0.236515611410141, "max": 0.5867400765419006}}
{"meta": {"group": "D", "topic_id": 75, "topic_size": 2, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "injury treatment", "stats": {"n_snippets": 2, "mean": 0.4176611304283142, "min": 0.320494145154953, "max": 0.514828085899353}}
{"meta": {"group": "D", "topic_id": 76, "topic_size": 2, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "statement accomplishment", "stats": {"n_snippets": 2, "mean": 0.5835416316986084, "min": 0.5728297233581543, "max": 0.5942535400390625}}
{"meta": {"group": "D", "topic_id": 77, "topic_size": 2, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "outliers handling", "stats": {"n_snippets": 2, "mean": 0.43732890486717224, "min": 0.4088238477706909, "max": 0.46583396196365356}}
{"meta": {"group": "D", "topic_id": 78, "topic_size": 2, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "improvement forecasting", "stats": {"n_snippets": 2, "mean": 0.3746974468231201, "min": 0.20403340458869934, "max": 0.5453614592552185}}
{"meta": {"group": "D", "topic_id": 79, "topic_size": 2, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "download issues", "stats": {"n_snippets": 2, "mean": 0.4569317102432251, "min": 0.45655184984207153, "max": 0.45731157064437866}}
{"meta": {"group": "D", "topic_id": 80, "topic_size": 2, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "peer editing issues", "stats": {"n_snippets": 2, "mean": 0.33748286962509155, "min": 0.2957286834716797, "max": 0.3792370557785034}}
{"meta": {"group": "D", "topic_id": 81, "topic_size": 2, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "update book refs", "stats": {"n_snippets": 2, "mean": 0.49029791355133057, "min": 0.4203569293022156, "max": 0.5602388978004456}}
{"meta": {"group": "D", "topic_id": 82, "topic_size": 2, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "rescuetime uninstall", "stats": {"n_snippets": 2, "mean": 0.5056290626525879, "min": 0.23806384205818176, "max": 0.7731942534446716}}
{"meta": {"group": "D", "topic_id": 83, "topic_size": 2, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "pab difference", "stats": {"n_snippets": 2, "mean": 0.5663427710533142, "min": 0.5609487295150757, "max": 0.5717368125915527}}
{"meta": {"group": "D", "topic_id": 84, "topic_size": 2, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "typo corrections", "stats": {"n_snippets": 2, "mean": 0.30475783348083496, "min": 0.13856343924999237, "max": 0.47095221281051636}}
{"meta": {"group": "D", "topic_id": 85, "topic_size": 2, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "section lecture hints", "stats": {"n_snippets": 2, "mean": 0.5676589012145996, "min": 0.443526029586792, "max": 0.6917917728424072}}
{"meta": {"group": "D", "topic_id": 86, "topic_size": 2, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "urgent answers", "stats": {"n_snippets": 2, "mean": 0.30596303939819336, "min": 0.2556275725364685, "max": 0.3562985062599182}}
{"meta": {"group": "D", "topic_id": 87, "topic_size": 2, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "statistical inference", "stats": {"n_snippets": 2, "mean": 0.29032522439956665, "min": 0.05381542816758156, "max": 0.526835024356842}}
{"meta": {"group": "D", "topic_id": 88, "topic_size": 2, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "linear regression assumptions", "stats": {"n_snippets": 2, "mean": 0.4782022535800934, "min": 0.40541964769363403, "max": 0.5509848594665527}}
{"meta": {"group": "D", "topic_id": 89, "topic_size": 2, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "week deadlines", "stats": {"n_snippets": 2, "mean": 0.5371140241622925, "min": 0.5332964658737183, "max": 0.5409316420555115}}
{"meta": {"group": "D", "topic_id": 90, "topic_size": 2, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "variable importance", "stats": {"n_snippets": 2, "mean": 0.3439822196960449, "min": 0.26701605319976807, "max": 0.4209483861923218}}
{"meta": {"group": "D", "topic_id": 91, "topic_size": 2, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "module help", "stats": {"n_snippets": 2, "mean": 0.22849293053150177, "min": 0.1003648117184639, "max": 0.35662105679512024}}
{"meta": {"group": "D", "topic_id": 92, "topic_size": 2, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "blood sugar levels", "stats": {"n_snippets": 2, "mean": 0.2734195590019226, "min": 0.22781911492347717, "max": 0.31902003288269043}}
{"meta": {"group": "D", "topic_id": 93, "topic_size": 2, "model_tag": "qwen_qwen-2.5-7b-instruct", "prompt_option": 1}, "label": "discordant pairs", "stats": {"n_snippets": 2, "mean": 0.27478066086769104, "min": 0.18187598884105682, "max": 0.36768531799316406}}
