{"meta": {"group": "D", "topic_id": 0, "topic_size": 1893, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "essay writing", "stats": {"n_snippets": 10, "mean": 0.31208646297454834, "min": 0.03764144331216812, "max": 0.5933792591094971}}
{"meta": {"group": "D", "topic_id": 1, "topic_size": 24, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "medical emergency response", "stats": {"n_snippets": 10, "mean": 0.2689463496208191, "min": 0.06529929488897324, "max": 0.41989511251449585}}
{"meta": {"group": "D", "topic_id": 2, "topic_size": 20, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "tech support", "stats": {"n_snippets": 10, "mean": 0.23414206504821777, "min": 0.09863400459289551, "max": 0.44332581758499146}}
{"meta": {"group": "D", "topic_id": 3, "topic_size": 15, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "install deducer error", "stats": {"n_snippets": 10, "mean": 0.4670926630496979, "min": 0.3203747272491455, "max": 0.7584747076034546}}
{"meta": {"group": "D", "topic_id": 4, "topic_size": 12, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "download slides", "stats": {"n_snippets": 10, "mean": 0.6406580209732056, "min": 0.4333355724811554, "max": 0.9332292079925537}}
{"meta": {"group": "D", "topic_id": 5, "topic_size": 11, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "histograms in sas", "stats": {"n_snippets": 10, "mean": 0.4854375422000885, "min": 0.2921791672706604, "max": 0.7068069577217102}}
{"meta": {"group": "D", "topic_id": 7, "topic_size": 10, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "spinal cord injuries", "stats": {"n_snippets": 10, "mean": 0.6053305864334106, "min": 0.3465242087841034, "max": 0.7532583475112915}}
{"meta": {"group": "D", "topic_id": 8, "topic_size": 9, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "person years", "stats": {"n_snippets": 9, "mean": 0.5085988640785217, "min": 0.329098105430603, "max": 0.7820295095443726}}
{"meta": {"group": "D", "topic_id": 9, "topic_size": 9, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "statement accomplishment", "stats": {"n_snippets": 9, "mean": 0.6147881150245667, "min": 0.35201495885849, "max": 0.8462156653404236}}
{"meta": {"group": "D", "topic_id": 10, "topic_size": 9, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "parkinsons disease", "stats": {"n_snippets": 9, "mean": 0.15805357694625854, "min": -0.041484951972961426, "max": 0.4476785659790039}}
{"meta": {"group": "D", "topic_id": 11, "topic_size": 8, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "easy compose", "stats": {"n_snippets": 8, "mean": 0.36569952964782715, "min": 0.15419358015060425, "max": 0.3976539969444275}}
{"meta": {"group": "D", "topic_id": 12, "topic_size": 7, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "course completion", "stats": {"n_snippets": 7, "mean": 0.23246121406555176, "min": 0.08603650331497192, "max": 0.4076571762561798}}
{"meta": {"group": "D", "topic_id": 13, "topic_size": 7, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "normal approximation", "stats": {"n_snippets": 7, "mean": 0.49709171056747437, "min": 0.401789128780365, "max": 0.576065182685852}}
{"meta": {"group": "D", "topic_id": 14, "topic_size": 7, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "ordinal scale", "stats": {"n_snippets": 7, "mean": 0.4862677752971649, "min": 0.2346319556236267, "max": 0.6119834184646606}}
{"meta": {"group": "D", "topic_id": 15, "topic_size": 6, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "multiple births", "stats": {"n_snippets": 6, "mean": 0.4206053912639618, "min": 0.0753391832113266, "max": 0.6190690398216248}}
{"meta": {"group": "D", "topic_id": 16, "topic_size": 6, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "slope and line", "stats": {"n_snippets": 6, "mean": 0.5527214407920837, "min": 0.4438796639442444, "max": 0.7424716353416443}}
{"meta": {"group": "D", "topic_id": 17, "topic_size": 6, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "getting help", "stats": {"n_snippets": 6, "mean": 0.36605212092399597, "min": 0.15893760323524475, "max": 0.5701563954353333}}
{"meta": {"group": "D", "topic_id": 18, "topic_size": 6, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "donor blood supply", "stats": {"n_snippets": 6, "mean": 0.5027413964271545, "min": 0.3719519376754761, "max": 0.6318671703338623}}
{"meta": {"group": "D", "topic_id": 19, "topic_size": 6, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "language learning", "stats": {"n_snippets": 6, "mean": 0.19764095544815063, "min": 0.07123292237520218, "max": 0.4114493727684021}}
{"meta": {"group": "D", "topic_id": 20, "topic_size": 6, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "electron trajectories", "stats": {"n_snippets": 6, "mean": 0.5349597334861755, "min": 0.26968491077423096, "max": 0.6976271867752075}}
{"meta": {"group": "D", "topic_id": 21, "topic_size": 5, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "rolling dice", "stats": {"n_snippets": 5, "mean": 0.624289333820343, "min": 0.5167655348777771, "max": 0.7746995091438293}}
{"meta": {"group": "D", "topic_id": 22, "topic_size": 5, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "editing demo exercises", "stats": {"n_snippets": 5, "mean": 0.5549209713935852, "min": 0.2739289700984955, "max": 0.6936200857162476}}
{"meta": {"group": "D", "topic_id": 23, "topic_size": 5, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "email issues", "stats": {"n_snippets": 5, "mean": 0.4135664105415344, "min": 0.33873772621154785, "max": 0.48394662141799927}}
{"meta": {"group": "D", "topic_id": 24, "topic_size": 5, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "beta smoking", "stats": {"n_snippets": 5, "mean": 0.22071973979473114, "min": 0.02643786370754242, "max": 0.3995496928691864}}
{"meta": {"group": "D", "topic_id": 25, "topic_size": 5, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "graphic way control", "stats": {"n_snippets": 5, "mean": 0.034094180911779404, "min": -0.10165198147296906, "max": 0.22303076088428497}}
{"meta": {"group": "D", "topic_id": 26, "topic_size": 5, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "p-value adjustment", "stats": {"n_snippets": 5, "mean": 0.4078412652015686, "min": 0.22737812995910645, "max": 0.5233181715011597}}
{"meta": {"group": "D", "topic_id": 27, "topic_size": 5, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "halt study", "stats": {"n_snippets": 5, "mean": 0.6956287622451782, "min": 0.5682175159454346, "max": 0.8176994323730469}}
{"meta": {"group": "D", "topic_id": 28, "topic_size": 5, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "alzheimers prevention", "stats": {"n_snippets": 5, "mean": 0.62061607837677, "min": 0.28545278310775757, "max": 0.785010814666748}}
{"meta": {"group": "D", "topic_id": 29, "topic_size": 5, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "quiz based", "stats": {"n_snippets": 5, "mean": 0.12914709746837616, "min": -0.004749493673443794, "max": 0.2922407388687134}}
{"meta": {"group": "D", "topic_id": 30, "topic_size": 5, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "null hypothesis", "stats": {"n_snippets": 5, "mean": 0.31814199686050415, "min": 0.13586635887622833, "max": 0.5785014033317566}}
{"meta": {"group": "D", "topic_id": 31, "topic_size": 5, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "fitness performance", "stats": {"n_snippets": 5, "mean": 0.5733101963996887, "min": 0.3834707736968994, "max": 0.6934620141983032}}
{"meta": {"group": "D", "topic_id": 32, "topic_size": 5, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "choosing a function", "stats": {"n_snippets": 5, "mean": 0.22714285552501678, "min": 0.07388640940189362, "max": 0.40764501690864563}}
{"meta": {"group": "D", "topic_id": 33, "topic_size": 5, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "frequency study", "stats": {"n_snippets": 5, "mean": 0.5436497926712036, "min": 0.4139332175254822, "max": 0.6919520497322083}}
{"meta": {"group": "D", "topic_id": 34, "topic_size": 5, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "survival probability", "stats": {"n_snippets": 5, "mean": 0.5392912030220032, "min": 0.34427452087402344, "max": 0.6262050271034241}}
{"meta": {"group": "D", "topic_id": 35, "topic_size": 5, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "find old posts", "stats": {"n_snippets": 5, "mean": 0.4207051396369934, "min": 0.26356232166290283, "max": 0.6468961834907532}}
{"meta": {"group": "D", "topic_id": 36, "topic_size": 4, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "vaccine simulation", "stats": {"n_snippets": 4, "mean": 0.6318832039833069, "min": 0.3417799174785614, "max": 0.7827852964401245}}
{"meta": {"group": "D", "topic_id": 37, "topic_size": 4, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "mock data", "stats": {"n_snippets": 4, "mean": 0.5312576293945312, "min": 0.4490167796611786, "max": 0.6212259531021118}}
{"meta": {"group": "D", "topic_id": 38, "topic_size": 4, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "module use statement", "stats": {"n_snippets": 4, "mean": 0.5014166831970215, "min": 0.47847113013267517, "max": 0.5208701491355896}}
{"meta": {"group": "D", "topic_id": 39, "topic_size": 4, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "fishers exact test", "stats": {"n_snippets": 4, "mean": 0.48996344208717346, "min": 0.2513519525527954, "max": 0.5949879884719849}}
{"meta": {"group": "D", "topic_id": 40, "topic_size": 4, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "coin flip probability", "stats": {"n_snippets": 4, "mean": 0.4396791160106659, "min": 0.2982501983642578, "max": 0.5301111936569214}}
{"meta": {"group": "D", "topic_id": 41, "topic_size": 3, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "downloading unit solutions", "stats": {"n_snippets": 3, "mean": 0.568101704120636, "min": 0.2801121473312378, "max": 0.7661271095275879}}
{"meta": {"group": "D", "topic_id": 42, "topic_size": 3, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "perfect tense", "stats": {"n_snippets": 3, "mean": 0.2082473784685135, "min": 0.049972254782915115, "max": 0.40754231810569763}}
{"meta": {"group": "D", "topic_id": 43, "topic_size": 3, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "browser issues", "stats": {"n_snippets": 3, "mean": 0.38207778334617615, "min": 0.3358842134475708, "max": 0.4422214925289154}}
{"meta": {"group": "D", "topic_id": 44, "topic_size": 3, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "common sense", "stats": {"n_snippets": 3, "mean": 0.6037551164627075, "min": 0.550006628036499, "max": 0.6829513311386108}}
{"meta": {"group": "D", "topic_id": 45, "topic_size": 3, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "square vs absolute", "stats": {"n_snippets": 3, "mean": 0.4958822727203369, "min": 0.3551730513572693, "max": 0.6573758125305176}}
{"meta": {"group": "D", "topic_id": 46, "topic_size": 3, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "professional writing", "stats": {"n_snippets": 3, "mean": 0.4020780622959137, "min": 0.26246410608291626, "max": 0.6629678010940552}}
{"meta": {"group": "D", "topic_id": 47, "topic_size": 3, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "kind help needed", "stats": {"n_snippets": 3, "mean": 0.5686594843864441, "min": 0.5287079811096191, "max": 0.5886351466178894}}
{"meta": {"group": "D", "topic_id": 48, "topic_size": 3, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "energy costs", "stats": {"n_snippets": 3, "mean": 0.11991846561431885, "min": 0.0203215554356575, "max": 0.24829640984535217}}
{"meta": {"group": "D", "topic_id": 49, "topic_size": 3, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "raised nevi", "stats": {"n_snippets": 3, "mean": 0.3649860918521881, "min": 0.24222365021705627, "max": 0.5744456648826599}}
{"meta": {"group": "D", "topic_id": 50, "topic_size": 3, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "increase dsst score", "stats": {"n_snippets": 3, "mean": 0.45635613799095154, "min": 0.3762627840042114, "max": 0.5401652455329895}}
{"meta": {"group": "D", "topic_id": 51, "topic_size": 3, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "signrank test", "stats": {"n_snippets": 3, "mean": 0.4322606027126312, "min": 0.33206599950790405, "max": 0.6308538913726807}}
{"meta": {"group": "D", "topic_id": 52, "topic_size": 3, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "cherrypicked data", "stats": {"n_snippets": 3, "mean": 0.36880752444267273, "min": 0.32339751720428467, "max": 0.4173162281513214}}
{"meta": {"group": "D", "topic_id": 53, "topic_size": 3, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "cheating question", "stats": {"n_snippets": 3, "mean": 0.3737998902797699, "min": 0.1331150233745575, "max": 0.745227575302124}}
{"meta": {"group": "D", "topic_id": 54, "topic_size": 3, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "slice order matters", "stats": {"n_snippets": 3, "mean": 0.4184032380580902, "min": 0.2586246728897095, "max": 0.6250491142272949}}
{"meta": {"group": "D", "topic_id": 55, "topic_size": 3, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "ratios and units", "stats": {"n_snippets": 3, "mean": 0.4787483215332031, "min": 0.3860599398612976, "max": 0.5450254678726196}}
{"meta": {"group": "D", "topic_id": 56, "topic_size": 3, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "act and wave", "stats": {"n_snippets": 3, "mean": 0.26457056403160095, "min": 0.1764453798532486, "max": 0.3377299904823303}}
{"meta": {"group": "D", "topic_id": 57, "topic_size": 3, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "exact vs chi", "stats": {"n_snippets": 3, "mean": 0.4559503495693207, "min": 0.39101502299308777, "max": 0.50112384557724}}
{"meta": {"group": "D", "topic_id": 58, "topic_size": 3, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "browser issues", "stats": {"n_snippets": 3, "mean": 0.39998936653137207, "min": 0.3239838182926178, "max": 0.4861627221107483}}
{"meta": {"group": "D", "topic_id": 59, "topic_size": 3, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "missing data", "stats": {"n_snippets": 3, "mean": 0.41896772384643555, "min": 0.27408915758132935, "max": 0.5939955115318298}}
{"meta": {"group": "D", "topic_id": 60, "topic_size": 3, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "percentages in mooc", "stats": {"n_snippets": 3, "mean": 0.4271559715270996, "min": 0.4271559417247772, "max": 0.4271559715270996}}
{"meta": {"group": "D", "topic_id": 61, "topic_size": 3, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "howcome answer", "stats": {"n_snippets": 3, "mean": 0.5582606792449951, "min": 0.46964800357818604, "max": 0.7242144346237183}}
{"meta": {"group": "D", "topic_id": 62, "topic_size": 3, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "got zeros peers", "stats": {"n_snippets": 3, "mean": 0.6092420816421509, "min": 0.6092420816421509, "max": 0.6092420816421509}}
{"meta": {"group": "D", "topic_id": 63, "topic_size": 3, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "number question", "stats": {"n_snippets": 3, "mean": 0.3264363706111908, "min": 0.22288087010383606, "max": 0.41807639598846436}}
{"meta": {"group": "D", "topic_id": 64, "topic_size": 3, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "prevalence calculations", "stats": {"n_snippets": 3, "mean": 0.4487539827823639, "min": 0.35564303398132324, "max": 0.504003643989563}}
{"meta": {"group": "D", "topic_id": 65, "topic_size": 2, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "predictive power", "stats": {"n_snippets": 2, "mean": 0.13270865380764008, "min": -0.013756360858678818, "max": 0.27917367219924927}}
{"meta": {"group": "D", "topic_id": 66, "topic_size": 2, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "alzheimers disease", "stats": {"n_snippets": 2, "mean": 0.51701819896698, "min": 0.4453905522823334, "max": 0.5886458158493042}}
{"meta": {"group": "D", "topic_id": 67, "topic_size": 2, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "wait bug fixed", "stats": {"n_snippets": 2, "mean": 0.46949607133865356, "min": 0.33621475100517273, "max": 0.6027774214744568}}
{"meta": {"group": "D", "topic_id": 68, "topic_size": 2, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "standard normal chart", "stats": {"n_snippets": 2, "mean": 0.6341344118118286, "min": 0.6039055585861206, "max": 0.6643632650375366}}
{"meta": {"group": "D", "topic_id": 69, "topic_size": 2, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "journal legality", "stats": {"n_snippets": 2, "mean": 0.5141918063163757, "min": 0.35746264457702637, "max": 0.6709209680557251}}
{"meta": {"group": "D", "topic_id": 70, "topic_size": 2, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "success probability", "stats": {"n_snippets": 2, "mean": 0.6350886225700378, "min": 0.5664334297180176, "max": 0.7037438154220581}}
{"meta": {"group": "D", "topic_id": 71, "topic_size": 2, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "pond waste management", "stats": {"n_snippets": 2, "mean": 0.3961694836616516, "min": 0.11266802251338959, "max": 0.6796709299087524}}
{"meta": {"group": "D", "topic_id": 72, "topic_size": 2, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "childhood conduct", "stats": {"n_snippets": 2, "mean": 0.4174925684928894, "min": 0.221488818526268, "max": 0.6134963035583496}}
{"meta": {"group": "D", "topic_id": 73, "topic_size": 2, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "deserved zeros", "stats": {"n_snippets": 2, "mean": 0.6185142993927002, "min": 0.5528007745742798, "max": 0.6842278838157654}}
{"meta": {"group": "D", "topic_id": 74, "topic_size": 2, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "missing solutions", "stats": {"n_snippets": 2, "mean": 0.46169888973236084, "min": 0.39020049571990967, "max": 0.533197283744812}}
{"meta": {"group": "D", "topic_id": 75, "topic_size": 2, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "treat injuries", "stats": {"n_snippets": 2, "mean": 0.3554897904396057, "min": 0.2333538830280304, "max": 0.47762569785118103}}
{"meta": {"group": "D", "topic_id": 76, "topic_size": 2, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "statement accomplishment", "stats": {"n_snippets": 2, "mean": 0.5835416316986084, "min": 0.5728297233581543, "max": 0.5942535400390625}}
{"meta": {"group": "D", "topic_id": 77, "topic_size": 2, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "outlier detection", "stats": {"n_snippets": 2, "mean": 0.4177883267402649, "min": 0.3819947838783264, "max": 0.453581839799881}}
{"meta": {"group": "D", "topic_id": 78, "topic_size": 2, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "skewed results", "stats": {"n_snippets": 2, "mean": 0.36160027980804443, "min": 0.297428160905838, "max": 0.42577242851257324}}
{"meta": {"group": "D", "topic_id": 79, "topic_size": 2, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "download module", "stats": {"n_snippets": 2, "mean": 0.739591121673584, "min": 0.7105728387832642, "max": 0.7686094641685486}}
{"meta": {"group": "D", "topic_id": 80, "topic_size": 2, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "editing text", "stats": {"n_snippets": 2, "mean": 0.4901523292064667, "min": 0.46310871839523315, "max": 0.5171959400177002}}
{"meta": {"group": "D", "topic_id": 81, "topic_size": 2, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "update reference books", "stats": {"n_snippets": 2, "mean": 0.6132762432098389, "min": 0.508177638053894, "max": 0.7183749079704285}}
{"meta": {"group": "D", "topic_id": 82, "topic_size": 2, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "rescuetime uninstall", "stats": {"n_snippets": 2, "mean": 0.5056290626525879, "min": 0.23806384205818176, "max": 0.7731942534446716}}
{"meta": {"group": "D", "topic_id": 83, "topic_size": 2, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "pab independence", "stats": {"n_snippets": 2, "mean": 0.590252161026001, "min": 0.5244863033294678, "max": 0.656018078327179}}
{"meta": {"group": "D", "topic_id": 84, "topic_size": 2, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "typo in table", "stats": {"n_snippets": 2, "mean": 0.36626285314559937, "min": 0.16791032254695892, "max": 0.5646153688430786}}
{"meta": {"group": "D", "topic_id": 85, "topic_size": 2, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "lecture hints", "stats": {"n_snippets": 2, "mean": 0.5093923211097717, "min": 0.3796962797641754, "max": 0.6390883922576904}}
{"meta": {"group": "D", "topic_id": 86, "topic_size": 2, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "submit answers", "stats": {"n_snippets": 2, "mean": 0.4476631283760071, "min": 0.27673065662384033, "max": 0.6185956001281738}}
{"meta": {"group": "D", "topic_id": 87, "topic_size": 2, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "statistical inference", "stats": {"n_snippets": 2, "mean": 0.29032522439956665, "min": 0.05381542816758156, "max": 0.526835024356842}}
{"meta": {"group": "D", "topic_id": 88, "topic_size": 2, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "normality assumption", "stats": {"n_snippets": 2, "mean": 0.34972137212753296, "min": 0.21033518016338348, "max": 0.48910757899284363}}
{"meta": {"group": "D", "topic_id": 89, "topic_size": 2, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "week challenges", "stats": {"n_snippets": 2, "mean": 0.5500357747077942, "min": 0.4717696011066437, "max": 0.6283019185066223}}
{"meta": {"group": "D", "topic_id": 90, "topic_size": 2, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "large question", "stats": {"n_snippets": 2, "mean": 0.2531901001930237, "min": 0.22151829302310944, "max": 0.28486189246177673}}
{"meta": {"group": "D", "topic_id": 91, "topic_size": 2, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "page access", "stats": {"n_snippets": 2, "mean": 0.29154765605926514, "min": 0.1486293375492096, "max": 0.4344659745693207}}
{"meta": {"group": "D", "topic_id": 92, "topic_size": 2, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "blood sugar levels", "stats": {"n_snippets": 2, "mean": 0.2734195590019226, "min": 0.22781911492347717, "max": 0.31902003288269043}}
{"meta": {"group": "D", "topic_id": 93, "topic_size": 2, "model_tag": "meta-llama_llama-3.1-8b-instruct", "prompt_option": 2}, "label": "discordant pairs", "stats": {"n_snippets": 2, "mean": 0.27478066086769104, "min": 0.18187598884105682, "max": 0.36768531799316406}}
