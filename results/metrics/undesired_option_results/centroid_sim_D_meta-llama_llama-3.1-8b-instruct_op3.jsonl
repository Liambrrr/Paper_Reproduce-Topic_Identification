{"group": "D", "topic_id": 0, "topic_size": 1893, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "essay discussion", "cosine": 0.3937910795211792}
{"group": "D", "topic_id": 1, "topic_size": 24, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "medical emergency", "cosine": 0.5509671568870544}
{"group": "D", "topic_id": 2, "topic_size": 20, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "tech support issue", "cosine": 0.512612521648407}
{"group": "D", "topic_id": 3, "topic_size": 15, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "install deducer", "cosine": 0.5651081800460815}
{"group": "D", "topic_id": 4, "topic_size": 12, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "download slides", "cosine": 0.8646488785743713}
{"group": "D", "topic_id": 5, "topic_size": 11, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "histograms in mooc", "cosine": 0.551108181476593}
{"group": "D", "topic_id": 6, "topic_size": 10, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "respiratory issues", "cosine": 0.4125904142856598}
{"group": "D", "topic_id": 7, "topic_size": 10, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "brain spinal cord", "cosine": 0.6108174920082092}
{"group": "D", "topic_id": 8, "topic_size": 9, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "person year follow", "cosine": 0.7796863317489624}
{"group": "D", "topic_id": 9, "topic_size": 9, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "statement accomplishment", "cosine": 0.7911099195480347}
{"group": "D", "topic_id": 10, "topic_size": 9, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "parkinsons disease", "cosine": 0.2398684173822403}
{"group": "D", "topic_id": 11, "topic_size": 8, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "submitting previous work", "cosine": 0.5761091113090515}
{"group": "D", "topic_id": 12, "topic_size": 7, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "mooc completion", "cosine": 0.22606025636196136}
{"group": "D", "topic_id": 13, "topic_size": 7, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "normal approximation", "cosine": 0.621310293674469}
{"group": "D", "topic_id": 14, "topic_size": 7, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "ordinal scale", "cosine": 0.6633076071739197}
{"group": "D", "topic_id": 15, "topic_size": 6, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "multiple births", "cosine": 0.6128063201904297}
{"group": "D", "topic_id": 16, "topic_size": 6, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "slope and line", "cosine": 0.7449820637702942}
{"group": "D", "topic_id": 17, "topic_size": 6, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "getting received help", "cosine": 0.5236769318580627}
{"group": "D", "topic_id": 18, "topic_size": 6, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "donor blood", "cosine": 0.5570980310440063}
{"group": "D", "topic_id": 19, "topic_size": 6, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "paste assignment", "cosine": 0.2830711901187897}
{"group": "D", "topic_id": 20, "topic_size": 6, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "electron trajectories", "cosine": 0.6578999757766724}
{"group": "D", "topic_id": 21, "topic_size": 5, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "rolling dice", "cosine": 0.7767314910888672}
{"group": "D", "topic_id": 22, "topic_size": 5, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "demo edit exercises", "cosine": 0.7641903758049011}
{"group": "D", "topic_id": 23, "topic_size": 5, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "webmail issues", "cosine": 0.4680914282798767}
{"group": "D", "topic_id": 24, "topic_size": 5, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "beta smoking", "cosine": 0.33598101139068604}
{"group": "D", "topic_id": 25, "topic_size": 5, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "correlation question", "cosine": 0.4864818751811981}
{"group": "D", "topic_id": 26, "topic_size": 5, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "pvalue adjustment", "cosine": 0.6909840703010559}
{"group": "D", "topic_id": 27, "topic_size": 5, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "recommended halt study", "cosine": 0.8829867839813232}
{"group": "D", "topic_id": 28, "topic_size": 5, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "antiinflammatory drugs prevent", "cosine": 0.784907877445221}
{"group": "D", "topic_id": 29, "topic_size": 5, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "read multiplier value", "cosine": 0.5363267660140991}
{"group": "D", "topic_id": 30, "topic_size": 5, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "null hypothesis", "cosine": 0.42465946078300476}
{"group": "D", "topic_id": 31, "topic_size": 5, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "cardiorespiratory performance", "cosine": 0.6778881549835205}
{"group": "D", "topic_id": 32, "topic_size": 5, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "choosing function", "cosine": 0.3721822500228882}
{"group": "D", "topic_id": 33, "topic_size": 5, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "frequency study", "cosine": 0.688069224357605}
{"group": "D", "topic_id": 34, "topic_size": 5, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "survival probability", "cosine": 0.6701046824455261}
{"group": "D", "topic_id": 35, "topic_size": 5, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "post search", "cosine": 0.5277592539787292}
{"group": "D", "topic_id": 36, "topic_size": 4, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "vaccine simulation", "cosine": 0.8004531264305115}
{"group": "D", "topic_id": 37, "topic_size": 4, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "mock class download", "cosine": 0.656252920627594}
{"group": "D", "topic_id": 38, "topic_size": 4, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "module repetition", "cosine": 0.7657618522644043}
{"group": "D", "topic_id": 39, "topic_size": 4, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "fishers exact test", "cosine": 0.6583958864212036}
{"group": "D", "topic_id": 40, "topic_size": 4, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "coin flip probability", "cosine": 0.5955129861831665}
{"group": "D", "topic_id": 41, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "downloading issues", "cosine": 0.5068055987358093}
{"group": "D", "topic_id": 42, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "perfect tense", "cosine": 0.2810927927494049}
{"group": "D", "topic_id": 43, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "submit arrows issue", "cosine": 0.46899330615997314}
{"group": "D", "topic_id": 44, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "common sense", "cosine": 0.7279626727104187}
{"group": "D", "topic_id": 45, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "absolute distance method", "cosine": 0.5434098243713379}
{"group": "D", "topic_id": 46, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "professional writing", "cosine": 0.5116032361984253}
{"group": "D", "topic_id": 47, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "help requests", "cosine": 0.5058121681213379}
{"group": "D", "topic_id": 48, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "prosthetic energy efficiency", "cosine": 0.531076967716217}
{"group": "D", "topic_id": 49, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "raised nevi", "cosine": 0.4234989583492279}
{"group": "D", "topic_id": 50, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "beta coefficient", "cosine": 0.5098789930343628}
{"group": "D", "topic_id": 51, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "signrank test", "cosine": 0.5513793230056763}
{"group": "D", "topic_id": 52, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "wrong data analysis", "cosine": 0.5723957419395447}
{"group": "D", "topic_id": 53, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "cheating question", "cosine": 0.49548715353012085}
{"group": "D", "topic_id": 54, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "card combinations", "cosine": 0.6601486802101135}
{"group": "D", "topic_id": 55, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "ratios and units", "cosine": 0.5919777750968933}
{"group": "D", "topic_id": 56, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "act matter occurs", "cosine": 0.21875399351119995}
{"group": "D", "topic_id": 57, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "exact test", "cosine": 0.4499029815196991}
{"group": "D", "topic_id": 58, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "browser issues", "cosine": 0.4812062382698059}
{"group": "D", "topic_id": 59, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "missing data plots", "cosine": 0.6591914296150208}
{"group": "D", "topic_id": 60, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "percentages use", "cosine": 0.6473117470741272}
{"group": "D", "topic_id": 61, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "howcome answer", "cosine": 0.6978205442428589}
{"group": "D", "topic_id": 62, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "got zeros peers", "cosine": 0.6092421412467957}
{"group": "D", "topic_id": 63, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "number question", "cosine": 0.4143969714641571}
{"group": "D", "topic_id": 64, "topic_size": 3, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "prevalence fractures", "cosine": 0.3717132806777954}
{"group": "D", "topic_id": 65, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "sensitivity specificity", "cosine": 0.3822280168533325}
{"group": "D", "topic_id": 66, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "alzheimers disease", "cosine": 0.5931581258773804}
{"group": "D", "topic_id": 67, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "assignment wait bug", "cosine": 0.6796810030937195}
{"group": "D", "topic_id": 68, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "standard normal chart", "cosine": 0.7349894046783447}
{"group": "D", "topic_id": 69, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "journal ethics", "cosine": 0.49361521005630493}
{"group": "D", "topic_id": 70, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "z-score calculation", "cosine": 0.3077003061771393}
{"group": "D", "topic_id": 71, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "health and climates", "cosine": 0.4383827745914459}
{"group": "D", "topic_id": 72, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "childhood conduct", "cosine": 0.491413950920105}
{"group": "D", "topic_id": 73, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "got zeroes really", "cosine": 0.7065818905830383}
{"group": "D", "topic_id": 74, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "posted mistake solutions", "cosine": 0.6427181959152222}
{"group": "D", "topic_id": 75, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "treat injuries", "cosine": 0.4067877531051636}
{"group": "D", "topic_id": 76, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "statement accomplishment", "cosine": 0.6379656791687012}
{"group": "D", "topic_id": 77, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "outlier detection", "cosine": 0.47128885984420776}
{"group": "D", "topic_id": 78, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "skew results", "cosine": 0.437137633562088}
{"group": "D", "topic_id": 79, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "download module", "cosine": 0.8279401659965515}
{"group": "D", "topic_id": 80, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "text editing", "cosine": 0.5192035436630249}
{"group": "D", "topic_id": 81, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "update textbook reference", "cosine": 0.6780176758766174}
{"group": "D", "topic_id": 82, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "uninstall rescuetime", "cosine": 0.6275768876075745}
{"group": "D", "topic_id": 83, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "pab independence", "cosine": 0.6613045334815979}
{"group": "D", "topic_id": 84, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "odds ratios", "cosine": 0.4201713502407074}
{"group": "D", "topic_id": 85, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "lecture hints", "cosine": 0.6011138558387756}
{"group": "D", "topic_id": 86, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "submit answers", "cosine": 0.5127801299095154}
{"group": "D", "topic_id": 87, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "statistical inference", "cosine": 0.3963695168495178}
{"group": "D", "topic_id": 88, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "linear regression assumption", "cosine": 0.5904242396354675}
{"group": "D", "topic_id": 89, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "week deadline", "cosine": 0.5958401560783386}
{"group": "D", "topic_id": 90, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "rsquare analysis", "cosine": 0.5430503487586975}
{"group": "D", "topic_id": 91, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "web page access", "cosine": 0.3340928852558136}
{"group": "D", "topic_id": 92, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "blood sugar", "cosine": 0.25031036138534546}
{"group": "D", "topic_id": 93, "topic_size": 2, "llm_model": "meta-llama/llama-3.1-8b-instruct", "llm_provider": "openai-compatible", "prompt_option": 3, "label": "discordant pairs", "cosine": 0.31689006090164185}
